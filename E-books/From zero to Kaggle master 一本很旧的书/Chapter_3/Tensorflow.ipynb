{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello Google Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个Tensorflow的常量，XXXX字符串，并命名greeting作为一个计算模块\n",
    "greeting = tf.constant('Hello Google Tensorflow!')\n",
    "# 启动一个会话\n",
    "sess = tf.Session()\n",
    "# 使用会话执行greeting计算模块\n",
    "\n",
    "result = sess.run(greeting)\n",
    "# 输出会话执行的结果\n",
    "print(result)\n",
    "# 关闭会话\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Tensorflow完成一次线性函数的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "linear = tf.add(product, tf.constant(2.0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(linear)\n",
    "    print (result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Tensorflow自定义一个线性分类器用于对“良/恶性乳腺癌肿瘤” 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../Datasets/Breast-Cancer/breast-cancer-train.csv')\n",
    "test = pd.read_csv('../Datasets/Breast-Cancer/breast-cancer-test.csv')\n",
    "\n",
    "\n",
    "X_train = np.float32(train[['Clump Thickness', 'Cell Size']].T)\n",
    "y_train = np.float32(train['Type'].T)\n",
    "X_test = np.float32(test[['Clump Thickness', 'Cell Size']].T)\n",
    "y_test = np.float32(test['Type'].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.7662109 -0.5509385]] [-0.0233511]\n",
      "200 [[0.09181824 0.03929571]] [-0.05895002]\n",
      "400 [[0.05969444 0.07467142]] [-0.0812626]\n",
      "600 [[0.05797697 0.07714197]] [-0.08589094]\n",
      "800 [[0.05786981 0.07738636]] [-0.086715]\n"
     ]
    }
   ],
   "source": [
    "b = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "y = tf.matmul(W, X_train) + b\n",
    "\n",
    "# 最小化方差\n",
    "loss = tf.reduce_mean(tf.square(y - y_train))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 启动图 (graph)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 拟合平面\n",
    "for step in range(0, 1000):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0:\n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_negative = test.loc[test['Type'] == 0][['Clump Thickness', 'Cell Size']]\n",
    "test_positive = test.loc[test['Type'] == 1][['Clump Thickness', 'Cell Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_negative['Clump Thickness'], test_negative['Cell Size'], marker='o', s = 200, c = 'red')\n",
    "plt.scatter(test_positive['Clump Thickness'], test_positive['Cell Size'], marker='x', s = 150, c = 'black')\n",
    "\n",
    "plt.xlabel('Clump Thickness')\n",
    "plt.ylabel('Cell Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx = np.arange(0, 12)\n",
    "ly = (0.5 - sess.run(b) - lx * sess.run(W)[0][0]) / sess.run(W)[0][1]\n",
    "\n",
    "\n",
    "plt.plot(lx, ly, color ='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "\n",
    "# Load dataset\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "# Split dataset into train / test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y,\n",
    "    test_size=0.25, random_state=33)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'histogram_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cffab040e521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorFlowLinearRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtf_lr_y_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skflow/estimators/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, logdir)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_training\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# Sets up model and trainer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;31m# Initialize model parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skflow/estimators/base.py\u001b[0m in \u001b[0;36m_setup_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Add histograms for X and y if they are floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_feeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_feeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'histogram_summary'"
     ]
    }
   ],
   "source": [
    "import skflow\n",
    "\n",
    "tf_lr = skflow.TensorFlowLinearRegressor(steps=10000, learning_rate=0.01, batch_size=50)\n",
    "tf_lr.fit(X_train, y_train)\n",
    "tf_lr_y_predict = tf_lr.predict(X_test)\n",
    "\n",
    "print( 'The mean absoluate error of Tensorflow Linear Regressor on boston dataset is', metrics.mean_absolute_error(tf_lr_y_predict, y_test))\n",
    "print ('The mean squared error of Tensorflow Linear Regressor on boston dataset is', metrics.mean_squared_error(tf_lr_y_predict, y_test))\n",
    "print ('The R-squared value of Tensorflow Linear Regressor on boston dataset is', metrics.r2_score(tf_lr_y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 640.79572\n",
      "Step #1001, epoch #125, avg. loss: 25.67079\n",
      "Step #2001, epoch #250, avg. loss: 3.89196\n",
      "Step #3001, epoch #375, avg. loss: 2.48694\n",
      "Step #4001, epoch #500, avg. loss: 1.91246\n",
      "Step #5001, epoch #625, avg. loss: 1.62935\n",
      "Step #6001, epoch #750, avg. loss: 1.45105\n",
      "Step #7001, epoch #875, avg. loss: 1.30371\n",
      "Step #8001, epoch #1000, avg. loss: 1.20998\n",
      "Step #9001, epoch #1125, avg. loss: 1.12960\n",
      "The mean absoluate error of Tensorflow DNN Regressor on boston dataset is 2.52779822988\n",
      "The mean squared error of Tensorflow DNN Regressor on boston dataset is 14.2553529174\n",
      "The R-squared value of Tensorflow DNN Regressor on boston dataset is 0.803518644048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf_dnn_regressor = skflow.TensorFlowDNNRegressor(hidden_units=[100, 40],\n",
    "    steps=10000, learning_rate=0.01, batch_size=50)\n",
    "\n",
    "\n",
    "tf_dnn_regressor.fit(X_train, y_train)\n",
    "tf_dnn_regressor_y_predict = tf_dnn_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "print 'The mean absoluate error of Tensorflow DNN Regressor on boston dataset is', metrics.mean_absolute_error(tf_dnn_regressor_y_predict, y_test)\n",
    "print 'The mean squared error of Tensorflow DNN Regressor on boston dataset is', metrics.mean_squared_error(tf_dnn_regressor_y_predict, y_test)\n",
    "print 'The R-squared value of Tensorflow DNN Regressor on boston dataset is', metrics.r2_score(tf_dnn_regressor_y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoluate error of Sklearn Random Forest Regressor on boston dataset is 2.50771653543\n",
      "The mean squared error of Sklearn Random Forest Regressor on boston dataset is 14.3741984252\n",
      "The R-squared value of Sklearn Random Forest Regressor on boston dataset is 0.796699065196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_predict = rfr.predict(X_test)\n",
    "\n",
    "print 'The mean absoluate error of Sklearn Random Forest Regressor on boston dataset is', metrics.mean_absolute_error(rfr_y_predict, y_test)\n",
    "print 'The mean squared error of Sklearn Random Forest Regressor on boston dataset is', metrics.mean_squared_error(rfr_y_predict, y_test)\n",
    "print 'The R-squared value of Sklearn Random Forest Regressor on boston dataset is', metrics.r2_score(rfr_y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
