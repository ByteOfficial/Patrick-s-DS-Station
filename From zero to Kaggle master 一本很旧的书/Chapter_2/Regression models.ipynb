{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM regression models\n",
    "## K-Nearest Neighbor regression models\n",
    "## Decision Tree regression models\n",
    "## Ensemble regression models\n",
    "### Patrick 🌰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.datasets导入波士顿房价数据读取器。\n",
    "from sklearn.datasets import load_boston\n",
    "# 从读取房价数据存储在变量boston中。\n",
    "boston = load_boston()\n",
    "# 输出数据描述。\n",
    "print (boston.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max target value is 50.0\n",
      "The min target value is 5.0\n",
      "The average target value is 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# 随机采样25%的数据构建测试样本，其余作为训练样本。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33, test_size=0.25)\n",
    "\n",
    "# 分析回归目标值的差异。\n",
    "print (\"The max target value is\", np.max(boston.target))\n",
    "print (\"The min target value is\", np.min(boston.target))\n",
    "print (\"The average target value is\", np.mean(boston.target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与测试数据标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.preprocessing导入数据标准化模块。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 分别初始化对特征和目标值的标准化器。\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "# must reshape the y_test and y_train\n",
    "y_test= y_test.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "# 分别对训练和测试数据的特征以及目标值进行标准化处理。\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)\n",
    "\n",
    "y_train = ss_y.fit_transform(y_train)\n",
    "y_test = ss_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型 Linear regression & SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.linear_model导入LinearRegression。\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 使用默认配置初始化线性回归器LinearRegression。\n",
    "lr = LinearRegression()\n",
    "# 使用训练数据进行参数估计。\n",
    "lr.fit(X_train, y_train)\n",
    "# 对测试数据进行回归预测。\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.linear_model导入SGDRegressor。\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# 使用默认配置初始化线性回归器SGDRegressor。\n",
    "sgdr = SGDRegressor()\n",
    "# 使用训练数据进行参数估计。\n",
    "sgdr.fit(X_train, y_train)\n",
    "# 对测试数据进行回归预测。\n",
    "sgdr_y_predict = sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of LinearRegression is 0.675795501452948\n",
      "The value of R-squared of LinearRegression is 0.675795501452948\n",
      "The mean squared error of LinearRegression is 25.139236520353457\n",
      "The mean absoluate error of LinearRegression is 3.5325325437053983\n"
     ]
    }
   ],
   "source": [
    "# 使用LinearRegression模型自带的评估模块，并输出评估结果。\n",
    "print ('The value of default measurement of LinearRegression is', lr.score(X_test, y_test))\n",
    "\n",
    "# 从sklearn.metrics依次导入r2_score、mean_squared_error以及mean_absoluate_error用于回归性能的评估。\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 使用r2_score模块，并输出评估结果。\n",
    "print ('The value of R-squared of LinearRegression is', r2_score(y_test, lr_y_predict))\n",
    "\n",
    "# 使用mean_squared_error模块，并输出评估结果。\n",
    "print ('The mean squared error of LinearRegression is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))\n",
    "\n",
    "# 使用mean_absolute_error模块，并输出评估结果。\n",
    "print ('The mean absoluate error of LinearRegression is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of default measurement of SGDRegressor is 0.6585897732863233\n",
      "The value of R-squared of SGDRegressor is 0.6585897732863233\n",
      "The mean squared error of SGDRegressor is 26.473390956285545\n",
      "The mean absoluate error of SGDRegressor is 3.549437134404973\n"
     ]
    }
   ],
   "source": [
    "# 使用SGDRegressor模型自带的评估模块，并输出评估结果。\n",
    "print ('The value of default measurement of SGDRegressor is', sgdr.score(X_test, y_test))\n",
    "\n",
    "# 使用r2_score模块，并输出评估结果。\n",
    "print ('The value of R-squared of SGDRegressor is', r2_score(y_test, sgdr_y_predict))\n",
    "\n",
    "# 使用mean_squared_error模块，并输出评估结果。\n",
    "print( 'The mean squared error of SGDRegressor is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))\n",
    "\n",
    "# 使用mean_absolute_error模块，并输出评估结果。\n",
    "print ('The mean absoluate error of SGDRegressor is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 线性回归器是最为简单、易用的回归模型。正是因为其对特征与回归目标之间的线性假设，从某种程度上说也是局限了其应用范围。特别是，现实生活中的许多实例数据的各个特征与回归目标之间，绝大多数不能保证严格的线性关系。尽管如此，在不清楚特征之间关系的前提下，我们仍然可以使用线性回归模型作为大多数科学实验的基线系统。\n",
    "* Linear Regressor is the simplest and easiest regression model. It is precisely because of its linear assumption between the feature and the regression goal that it limits the scope of its application to some extent. In particular, the vast majority of the characteristics of many instances of real-life data and regression goals do not guarantee a strictly linear relationship. Nevertheless, we can still use linear regression models as the baseline system for most scientific experiments without knowing the relationship between features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机回归\n",
    "* 使用三种不同核函数配置的支持向量机回归模型进行训练，并且分别对测试数据作出预测\n",
    "* 对三种核函数配置下的支持向量机回归模型在相同测试集上进行性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.svm中导入支持向量机（回归）模型。\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# 使用线性核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "linear_svr = SVR(kernel='linear')\n",
    "linear_svr.fit(X_train, y_train)\n",
    "linear_svr_y_predict = linear_svr.predict(X_test)\n",
    "\n",
    "# 使用多项式核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "poly_svr = SVR(kernel='poly')\n",
    "poly_svr.fit(X_train, y_train)\n",
    "poly_svr_y_predict = poly_svr.predict(X_test)\n",
    "\n",
    "# 使用径向基核函数配置的支持向量机进行回归训练，并且对测试样本进行预测。\n",
    "rbf_svr = SVR(kernel='rbf')\n",
    "rbf_svr.fit(X_train, y_train)\n",
    "rbf_svr_y_predict = rbf_svr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of linear SVR is 0.650659546421538\n",
      "The mean squared error of linear SVR is 27.088311013556027\n",
      "The mean absoluate error of linear SVR is 3.4328013877599624\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE和MAE指标对三种配置的支持向量机（回归）模型在相同测试集上进行性能评估。\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "print ('R-squared value of linear SVR is', linear_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of linear SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict)))\n",
    "print ('The mean absoluate error of linear SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(linear_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of Poly SVR is 0.40365065102550846\n",
      "The mean squared error of Poly SVR is 46.24170053103929\n",
      "The mean absoluate error of Poly SVR is 3.73840737104651\n"
     ]
    }
   ],
   "source": [
    "print( 'R-squared value of Poly SVR is', poly_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of Poly SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict)))\n",
    "print ('The mean absoluate error of Poly SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(poly_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RBF SVR is 0.7559887416340944\n",
      "The mean squared error of RBF SVR is 18.920948861538733\n",
      "The mean absoluate error of RBF SVR is 2.6067819999501114\n"
     ]
    }
   ],
   "source": [
    "print ('R-squared value of RBF SVR is', rbf_svr.score(X_test, y_test))\n",
    "print ('The mean squared error of RBF SVR is', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict)))\n",
    "print ('The mean absoluate error of RBF SVR is', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rbf_svr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 展示了不同配置模型在相同数据上所表现的性能差异，该系列模型还可以通过配置不同的核函数来改变模型性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K 临近回归\n",
    "* 使用不同配置的K 临近回归模型对美国波士顿房价数据进行回归预测\n",
    "* 对两种不同配置的K 临近回归模型在美国波士顿房价数据上进行预测性能的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.neighbors导入KNeighborRegressor（K近邻回归器）。\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 初始化K近邻回归器，并且调整配置，使得预测的方式为平均回归：weights='uniform'。\n",
    "uni_knr = KNeighborsRegressor(weights='uniform')\n",
    "uni_knr.fit(X_train, y_train)\n",
    "uni_knr_y_predict = uni_knr.predict(X_test)\n",
    "\n",
    "# 初始化K近邻回归器，并且调整配置，使得预测的方式为根据距离加权回归：weights='distance'。\n",
    "dis_knr = KNeighborsRegressor(weights='distance')\n",
    "dis_knr.fit(X_train, y_train)\n",
    "dis_knr_y_predict = dis_knr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of uniform-weighted KNeighorRegression: 0.6907212176346006\n",
      "The mean squared error of uniform-weighted KNeighorRegression: 23.981877165354337\n",
      "The mean absoluate error of uniform-weighted KNeighorRegression 2.9650393700787396\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE三种指标对平均回归配置的K近邻模型在测试集上进行性能评估。\n",
    "print ('R-squared value of uniform-weighted KNeighorRegression:', uni_knr.score(X_test, y_test))\n",
    "print ('The mean squared error of uniform-weighted KNeighorRegression:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict)))\n",
    "print ('The mean absoluate error of uniform-weighted KNeighorRegression', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(uni_knr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of distance-weighted KNeighorRegression: 0.7201094821421603\n",
      "The mean squared error of distance-weighted KNeighorRegression: 21.703073090490353\n",
      "The mean absoluate error of distance-weighted KNeighorRegression: 2.801125502210876\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE三种指标对根据距离加权回归配置的K近邻模型在测试集上进行性能评估。\n",
    "print ('R-squared value of distance-weighted KNeighorRegression:', dis_knr.score(X_test, y_test))\n",
    "print ('The mean squared error of distance-weighted KNeighorRegression:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict)))\n",
    "print ('The mean absoluate error of distance-weighted KNeighorRegression:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dis_knr_y_predict))\t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归树\n",
    "* 从预测值连续这个意义上严格地讲，回归树不能称为“回归算法”。因为回归树的叶节点返回的是“一团“ 训练数据的平均值，而不是具体的、连续的预测值。\n",
    "* 使用回归树对波士顿房价训练数据进行学习，并对测试数据进行预测\n",
    "* 对单一回归树模型在美国波士顿房价预测数据上的预测性能进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.tree中导入DecisionTreeRegressor。\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# 使用默认配置初始化DecisionTreeRegressor。\n",
    "dtr = DecisionTreeRegressor()\n",
    "# 用波士顿房价的训练数据构建回归树。\n",
    "dtr.fit(X_train, y_train)\n",
    "# 使用默认配置的单一回归树对测试数据进行预测，并将预测值存储在变量dtr_y_predict中。\n",
    "dtr_y_predict = dtr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of DecisionTreeRegressor: 0.6894984401640106\n",
      "The mean squared error of DecisionTreeRegressor: 24.07669291338583\n",
      "The mean absoluate error of DecisionTreeRegressor: 3.160629921259843\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的回归树在测试集上进行性能评估。\n",
    "print ('R-squared value of DecisionTreeRegressor:', dtr.score(X_test, y_test))\n",
    "print ('The mean squared error of DecisionTreeRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict)))\n",
    "print ('The mean absoluate error of DecisionTreeRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 系统的介绍了决策（分类）树与回归树之后，可以总结这类树模型的**优点：**\n",
    "1. 树模型可以解决非线性特征的问题；\n",
    "2. 树模型不要求对特征标准化和统一量化，即数值型和类别型特征都可以直接被应用在树模型的构建和预测过程中；\n",
    "3. 因为上述原因，树模型也可以直观地输出决策过程，使得预测结果具有可解释性。\n",
    "* **同时，树模型也有一些显著的缺陷：**\n",
    "1. 正是因为树模型可以解决复杂的非线性拟合问题，所以更加容易因为模型搭建过于复杂而丧失对新数据预测的精度（泛化力）；\n",
    "2. 树模型从上至下的预测流程会因为数据细微的更改而发生较大的结构变化，因此预测稳定想较差；\n",
    "3. 依托训练数据构建最佳树模型是NP难问题，即在有限时间内无法找到最优解的问题，因此我们所使用类似贪婪算法的解法只能找到一些次优解，这也是为什么我们经常结束集成模型，在多个次优解中寻觅更高的模型性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成模型（回归）\n",
    "* 极端随机森林（Eextremely Randomized Trees） 与普通随机森林模型不同的是，极端随机森林在每当构建一棵树的分裂节点（node）的时候，不会任意地选取特征，而是先随机手机一部分特征，然后利用信息熵（information gain） 和基尼不纯性（Gini Impurity)等指标挑选最佳的节点特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.ensemble中导入RandomForestRegressor、ExtraTreesGressor以及GradientBoostingRegressor。\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "# 使用RandomForestRegressor训练模型，并对测试数据做出预测，结果存储在变量rfr_y_predict中。\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_predict = rfr.predict(X_test)\n",
    "\n",
    "# 使用ExtraTreesRegressor训练模型，并对测试数据做出预测，结果存储在变量etr_y_predict中。\n",
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(X_train, y_train)\n",
    "etr_y_predict = etr.predict(X_test)\n",
    "\n",
    "# 使用GradientBoostingRegressor训练模型，并对测试数据做出预测，结果存储在变量gbr_y_predict中。\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_predict = gbr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RandomForestRegressor: 0.7904039225449876\n",
      "The mean squared error of RandomForestRegressor: 16.252351181102362\n",
      "The mean absoluate error of RandomForestRegressor: 2.427401574803149\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的随机回归森林在测试集上进行性能评估。\n",
    "print ('R-squared value of RandomForestRegressor:', rfr.score(X_test, y_test))\n",
    "print ('The mean squared error of RandomForestRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict)))\n",
    "print ('The mean absoluate error of RandomForestRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(rfr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of ExtraTreesRegressor: 0.8237325190594427\n",
      "The mean squared error of  ExtraTreesRegessor: 13.668008661417323\n",
      "The mean absoluate error of ExtraTreesRegessor: 2.3737795275590554\n",
      "{(0.05950056111756904, 'INDUS'), (0.03608112426859637, 'TAX'), (0.3041872533259853, 'LSTAT'), (0.04372876118169809, 'NOX'), (0.015833329972827086, 'CHAS'), (0.019750503274310577, 'PTRATIO'), (0.02074390785570981, 'CRIM'), (0.01217830614762584, 'RAD'), (0.03550605742418185, 'DIS'), (0.4196553958498484, 'RM'), (0.01479100178223286, 'AGE'), (0.0027600352520164013, 'ZN'), (0.01528376254739847, 'B')}\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的极端回归森林在测试集上进行性能评估。\n",
    "print ('R-squared value of ExtraTreesRegressor:', etr.score(X_test, y_test))\n",
    "print ('The mean squared error of  ExtraTreesRegessor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict)))\n",
    "print ('The mean absoluate error of ExtraTreesRegessor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(etr_y_predict)))\n",
    "\n",
    "# 利用训练好的极端回归森林模型，输出每种特征对预测目标的贡献度。\n",
    "\n",
    "print (set(zip(etr.feature_importances_ , boston.feature_names)))\n",
    "# print (np.array(etr.feature_importances_ , boston.feature_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of GradientBoostingRegressor: 0.828755989313912\n",
      "The mean squared error of GradientBoostingRegressor: 13.27848227468911\n",
      "The mean absoluate error of GradientBoostingRegressor: 2.3076587315993566\n"
     ]
    }
   ],
   "source": [
    "# 使用R-squared、MSE以及MAE指标对默认配置的梯度提升回归树在测试集上进行性能评估。\n",
    "print ('R-squared value of GradientBoostingRegressor:', gbr.score(X_test, y_test))\n",
    "print ('The mean squared error of GradientBoostingRegressor:', mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict)))\n",
    "print ('The mean absoluate error of GradientBoostingRegressor:', mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(gbr_y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 多种经典回归模型在“美国波士顿房价预测”问题的回归预测能力排名\n",
    "* GradientBoostingRegressor\n",
    "* ExtraTreesRegressor\n",
    "* RandomForestRegressor\n",
    "* SVM Regressor （RBF Kernel）\n",
    "* KNN Regressor （Distance-weighted）\n",
    "* DecisionTreeRegressor\n",
    "* KNN Regressor（Uniform-weighted）\n",
    "* LinearRegressor\n",
    "* SGDRegressor\n",
    "* SVM Regressor （Linear Kernel）\n",
    "* SVM Regressor （Poly Kernel）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
