{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patrick 🌰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: qureshi@bmerh185.bnr.ca (Emran Qureshi)\n",
      "Subject: Re: Europe vs. Muslim Bosnians\n",
      "Organization: Bell-Northern Research, Ottawa, Canada\n",
      "Lines: 26\n",
      "\n",
      "In article <C6x81M.EJF@news.cis.umn.edu> prabhak@giga.cs.umn.edu (Satya Prabhakar) writes:\n",
      ">(mohamed.s.sadek) writes:\n",
      ">>\n",
      ">>I like what Mr. Joseph Biden had to say yesterday 5/11/93 in the senate.\n",
      ">>\n",
      ">>Condemening the european lack of action and lack of support to us plans \n",
      ">>and calling that \"moral rape\".\n",
      ">>\n",
      ">>He went on to say that the reason for that is \"out right religious BIGOTRY\"\n",
      ">\n",
      ">Actually, this strife in Yugoslavia goes back a long way. Bosinan Muslims,\n",
      ">in collaboration with the Nazis, did to Serbians after the first world\n",
      ">war what Serbs are doing to Muslims now. This is not a fresh case of\n",
      ">ethnic cleansing but just another chapter in the continuing saga\n",
      ">of intense mutual hatred, destruction,... Not taking sides in this\n",
      ">perpetual war does not amount to religious bigotry. It could just\n",
      ">be helplessness with regards to bringing peace to a region that does\n",
      ">not even know the meaning of the word.\n",
      ">\n",
      ">Satya Prabhakar\n",
      ">--\n",
      "\n",
      "Yeah right, sorta like the Indian sub-contient, eh?\n",
      "\n",
      "Regards,\n",
      "Emran\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.datasets里导入新闻数据抓取器fetch_20newsgroups。\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# 与之前预存的数据不同，fetch_20newsgroups需要即时从互联网下载数据。\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "# 查验数据规模和细节。\n",
    "print( len(news.data))\n",
    "print( news.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.model_selection 导入 train_test_split。\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 随机采样25%的数据样本作为测试集。\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.feature_extraction.text里导入用于文本特征向量转化模块。详细介绍请读者参考3.1.1.1 特征抽取一节。\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)\n",
    "\n",
    "# 从sklearn.naive_bayes里导入朴素贝叶斯模型。\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 从使用默认配置初始化朴素贝叶斯模型。\n",
    "mnb = MultinomialNB()\n",
    "# 利用训练数据对模型参数进行估计。\n",
    "mnb.fit(X_train, y_train)\n",
    "# 对测试样本进行类别预测，结果存储在变量y_predict中。\n",
    "y_predict = mnb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes Classifier is 0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.metrics里导入classification_report用于详细的分类性能报告。\n",
    "from sklearn.metrics import classification_report\n",
    "print ('The accuracy of Naive Bayes Classifier is', mnb.score(X_test, y_test))\n",
    "print (classification_report(y_test, y_predict, target_names = news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 朴素贝叶斯模型被广泛应用于海量互联网文本分类任务。由于其较强的特征条件独立假设，使得模型预测所需要估计的参数规模从幂指数量级向线性量级减少，极大地节约了内存消耗和计算时间。但是，也正是受这种强假设的限制，模型训练时无法将各个特征之间的联系考量在内，使得该模型在其他数据特征关联性较强的分类任务上的性能表现不佳。\n",
    "* The naive Bayesian model is widely used in massive Internet text classification tasks. Due to its strong independent assumption of feature conditions, the estimated parameter size required for model prediction is reduced from the power index to the linear magnitude, which greatly saves memory consumption and computation time. However, it is also limited by this strong hypothesis that the model can't consider the connection between each feature during the training, which makes the model perform poorly on other classification tasks with strong data feature relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
