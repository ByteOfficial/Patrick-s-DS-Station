{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_contents = pd.read_table(\"../data/u.data\",\n",
    "                                    names=[\"user\", \"movie\", \"rating\", \"timestamp\"])\n",
    "\n",
    "df_utility = pd.pivot_table(data=df_ratings_contents, \n",
    "                            values='rating', \n",
    "                            index='user', \n",
    "                            columns='movie', \n",
    "                            fill_value=0)\n",
    "\n",
    "df_utility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utility.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_user_id = df_ratings_contents.user.max()\n",
    "highest_movie_id = df_ratings_contents.movie.max()\n",
    "ratings_mat = sparse.lil_matrix((highest_user_id, highest_movie_id))\n",
    "\n",
    "for _, row in df_ratings_contents.iterrows():\n",
    "    # subtract 1 from id's due to match 0 indexing\n",
    "    ratings_mat[row.user-1, row.movie-1] = row.rating\n",
    "\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def fit_nmf(M,k):\n",
    "    nmf = NMF(n_components=k)\n",
    "    nmf.fit(M)\n",
    "    W = nmf.transform(M);\n",
    "    H = nmf.components_;\n",
    "    err = nmf.reconstruction_err_\n",
    "    return W,H,err\n",
    "\n",
    "# decompose\n",
    "W,H,err = fit_nmf(ratings_mat,200)\n",
    "print(err)\n",
    "print(W.shape,H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "ratings_mat_fitted = W.dot(H)\n",
    "errs = np.array((ratings_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array((ratings_mat.todense()).flatten()).squeeze()>0\n",
    "\n",
    "mse = np.mean(errs[mask]**2)\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print(mse)\n",
    "print(average_abs_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 100\n",
    "n = 10\n",
    "\n",
    "pred_ratings = ratings_mat_fitted[user_id,:]\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check errors\n",
    "# truth\n",
    "ratings_true = ratings_mat[user_id, items_rated_by_this_user].todense()\n",
    "# prediction\n",
    "ratings_pred = pred_ratings[items_rated_by_this_user]\n",
    "print(list(zip(np.array(ratings_true).squeeze(),ratings_pred)))\n",
    "err_one_user = ratings_true-ratings_pred\n",
    "print(err_one_user)\n",
    "print(abs(err_one_user).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UVD/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def fit_uvd(M,k):\n",
    "    # use TruncatedSVD to realize UVD\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=7, random_state=0)\n",
    "    svd.fit(M)\n",
    "\n",
    "    V = svd.components_\n",
    "    U = svd.transform(M) # effectively, it's doing: U = M.dot(V.T)\n",
    "    # we can ignore svd.singular_values_ for our purpose\n",
    "    \n",
    "    # why we can do this?\n",
    "    # recall: \n",
    "    # SVD start from u*s*v=M => u*s=M*v.T, where M*v.T is our transformation above to get U in UVD\n",
    "    # so the above U is effectively u*s in SVD\n",
    "    # that's why U*V = u*s*v = M our original matrix\n",
    "    # there are many ways to understand it!\n",
    "    # here we by-passed singular values.\n",
    "    \n",
    "    return U,V, svd\n",
    "\n",
    "# decompose\n",
    "U,V,svd = fit_uvd(ratings_mat,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "ratings_mat_fitted = U.dot(V) # U*V\n",
    "\n",
    "\n",
    "# recall: U = M.dot(V.T), then this is M.dot(V.T).dot(V)\n",
    "# original M is transformed to new space, then transformed back\n",
    "# this is another way to understand it!\n",
    "\n",
    "# calculate errs\n",
    "errs = np.array((ratings_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array((ratings_mat.todense()).flatten()).squeeze()>0\n",
    "\n",
    "mse = np.mean(errs[mask]**2)\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print(mse)\n",
    "print(average_abs_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with another way to reconstruct matrix\n",
    "# with the above \"tranformed to the new space and back\" language\n",
    "# without the UV language, we can do:\n",
    "\n",
    "# reconstruct M with inverse_transform\n",
    "ratings_mat_fitted_2 = svd.inverse_transform(svd.transform(ratings_mat))\n",
    "ratings_mat_fitted = U.dot(V)\n",
    "print(sum(sum(ratings_mat_fitted - ratings_mat_fitted_2)))\n",
    "# they are just equivalent!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 100\n",
    "n = 10\n",
    "\n",
    "pred_ratings = ratings_mat_fitted[user_id,:]\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check errors\n",
    "# truth\n",
    "ratings_true = ratings_mat[user_id, items_rated_by_this_user].todense()\n",
    "# prediction\n",
    "ratings_pred = pred_ratings[items_rated_by_this_user]\n",
    "print(list(zip(np.array(ratings_true).squeeze(),ratings_pred)))\n",
    "err_one_user = ratings_true-ratings_pred\n",
    "print(err_one_user)\n",
    "print(abs(err_one_user).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
